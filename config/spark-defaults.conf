# config/spark-defaults.conf

# ⬇️ Indique le master Spark
spark.master                     local[*]

# ⬇️ Active Delta Lake
spark.sql.extensions             io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog  org.apache.spark.sql.delta.catalog.DeltaCatalog

# ⬇️ Charge les packages nécessaires (Delta + Kafka)
spark.jars.packages              io.delta:delta-spark_2.12:3.2.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0
